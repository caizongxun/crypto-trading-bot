#!/usr/bin/env python3\n\"\"\"\nML Model Optimization Script\n\nAutomates testing of different optimization strategies:\n1. Profit threshold adjustment\n2. Class weight adjustment\n3. Feature engineering\n\nUsage:\n    python optimize_model.py --strategy threshold\n    python optimize_model.py --strategy weight\n    python optimize_model.py --strategy features\n\"\"\"\n\nimport sys\nimport json\nimport subprocess\nfrom pathlib import Path\nfrom datetime import datetime\nimport pandas as pd\n\n\ndef run_training(lookback, profit_threshold=None, scale_pos_weight=None, strategy_name=\"\"):\n    \"\"\"\n    Run training with specific parameters\n    Returns: model config dict\n    \"\"\"\n    cmd = [\n        \"python\",\n        \"train_ml_classifier.py\",\n        f\"--lookback={lookback}\",\n    ]\n    \n    if profit_threshold is not None:\n        cmd.append(f\"--profit-threshold={profit_threshold}\")\n    \n    if scale_pos_weight is not None:\n        cmd.append(f\"--scale-pos-weight={scale_pos_weight}\")\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"Training: {strategy_name}\")\n    print(f\"Command: {' '.join(cmd)}\")\n    print(f\"{'='*80}\\n\")\n    \n    result = subprocess.run(cmd, capture_output=True, text=True)\n    \n    if result.returncode != 0:\n        print(f\"Error: {result.stderr}\")\n        return None\n    \n    print(result.stdout)\n    \n    # Load config\n    config_path = Path(\"ml_models/config_BTCUSDT_15m.json\")\n    if config_path.exists():\n        with open(config_path) as f:\n            return json.load(f)\n    return None\n\n\ndef strategy_threshold_optimization():\n    \"\"\"\n    Strategy 1: Test different profit thresholds\n    \"\"\"\n    print(\"\\n\" + \"*\" * 80)\n    print(\"STRATEGY 1: PROFIT THRESHOLD OPTIMIZATION\")\n    print(\"*\" * 80)\n    \n    thresholds = [0.0005, 0.001, 0.0015, 0.002, 0.003]\n    results = []\n    \n    for threshold in thresholds:\n        config = run_training(\n            lookback=5000,\n            profit_threshold=threshold,\n            strategy_name=f\"Threshold {threshold*100:.2f}%\"\n        )\n        \n        if config:\n            results.append({\n                'strategy': f'threshold_{threshold}',\n                'threshold': threshold,\n                'accuracy': config.get('accuracy', 0),\n                'true_count': config.get('true_signals', 0),\n                'false_count': config.get('false_signals', 0),\n                'weighted_f1': config.get('weighted_f1', 0),\n            })\n    \n    # Display results comparison\n    print(\"\\n\" + \"=\" * 80)\n    print(\"THRESHOLD OPTIMIZATION RESULTS COMPARISON\")\n    print(\"=\" * 80)\n    \n    df_results = pd.DataFrame(results)\n    print(df_results.to_string(index=False))\n    \n    # Save results\n    output_file = f\"optimization_results_threshold_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    with open(output_file, 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    print(f\"\\nResults saved to: {output_file}\")\n    \n    # Recommendation\n    best = max(results, key=lambda x: x['accuracy'])\n    print(f\"\\n✓ Best threshold by accuracy: {best['threshold']*100:.2f}%\")\n    print(f\"  Accuracy: {best['accuracy']:.4f}\")\n    print(f\"  True Signals: {best['true_count']}\")\n    print(f\"  False Signals: {best['false_count']}\")\n    \n    return results\n\n\ndef strategy_class_weight_optimization():\n    \"\"\"\n    Strategy 2: Test different class weights\n    Requires modification to model_training.py first\n    \"\"\"\n    print(\"\\n\" + \"*\" * 80)\n    print(\"STRATEGY 2: CLASS WEIGHT OPTIMIZATION\")\n    print(\"*\" * 80)\n    print(\"\\nNote: This strategy requires code modification first.\")\n    print(\"See: ml_classifier/model_training.py\\n\")\n    \n    weights = [1.0, 1.5, 2.0, 2.5, 3.0]\n    results = []\n    \n    # This will only work if scale_pos_weight is implemented\n    for weight in weights:\n        config = run_training(\n            lookback=5000,\n            scale_pos_weight=weight,\n            strategy_name=f\"Class Weight {weight}\"\n        )\n        \n        if config:\n            results.append({\n                'strategy': f'weight_{weight}',\n                'scale_pos_weight': weight,\n                'accuracy': config.get('accuracy', 0),\n                'true_count': config.get('true_signals', 0),\n                'false_count': config.get('false_signals', 0),\n                'weighted_f1': config.get('weighted_f1', 0),\n            })\n    \n    # Display results\n    if results:\n        print(\"\\n\" + \"=\" * 80)\n        print(\"CLASS WEIGHT OPTIMIZATION RESULTS\")\n        print(\"=\" * 80)\n        \n        df_results = pd.DataFrame(results)\n        print(df_results.to_string(index=False))\n        \n        # Save results\n        output_file = f\"optimization_results_weight_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n        with open(output_file, 'w') as f:\n            json.dump(results, f, indent=2)\n        \n        print(f\"\\nResults saved to: {output_file}\")\n        \n        best = max(results, key=lambda x: x['accuracy'])\n        print(f\"\\n✓ Best weight by accuracy: {best['scale_pos_weight']}\")\n        print(f\"  Accuracy: {best['accuracy']:.4f}\")\n    \n    return results\n\n\ndef strategy_hold_period_optimization():\n    \"\"\"\n    Strategy 3: Test different hold periods\n    \"\"\"\n    print(\"\\n\" + \"*\" * 80)\n    print(\"STRATEGY 3: HOLD PERIOD OPTIMIZATION\")\n    print(\"*\" * 80)\n    \n    hold_periods = [2, 3, 4, 5, 7]\n    results = []\n    \n    for period in hold_periods:\n        # Would need to modify train_ml_classifier to support this\n        config = run_training(\n            lookback=5000,\n            strategy_name=f\"Hold Period {period}\"\n        )\n        \n        if config:\n            results.append({\n                'strategy': f'hold_period_{period}',\n                'hold_period': period,\n                'accuracy': config.get('accuracy', 0),\n                'weighted_f1': config.get('weighted_f1', 0),\n            })\n    \n    return results\n\n\ndef compare_all_strategies():\n    \"\"\"\n    Run all optimization strategies and create comparison report\n    \"\"\"\n    print(\"\\n\" + \"#\" * 80)\n    print(\"# COMPREHENSIVE MODEL OPTIMIZATION\")\n    print(\"#\" * 80)\n    \n    all_results = {\n        'timestamp': datetime.now().isoformat(),\n        'baseline': {\n            'accuracy': 0.5499,\n            'true_recall': 0.2069,\n            'true_precision': 0.4719,\n        },\n        'threshold_results': [],\n        'weight_results': [],\n    }\n    \n    # Strategy 1: Threshold\n    print(\"\\nPhase 1: Testing profit thresholds...\")\n    threshold_results = strategy_threshold_optimization()\n    all_results['threshold_results'] = threshold_results\n    \n    # Strategy 2: Class Weight (if supported)\n    print(\"\\nPhase 2: Testing class weights...\")\n    try:\n        weight_results = strategy_class_weight_optimization()\n        all_results['weight_results'] = weight_results\n    except Exception as e:\n        print(f\"Class weight optimization skipped: {e}\")\n    \n    # Save comprehensive report\n    report_file = f\"optimization_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n    with open(report_file, 'w') as f:\n        json.dump(all_results, f, indent=2)\n    \n    print(f\"\\n✓ Complete report saved to: {report_file}\")\n    \n    # Print summary\n    print(\"\\n\" + \"=\" * 80)\n    print(\"OPTIMIZATION SUMMARY\")\n    print(\"=\" * 80)\n    \n    print(\"\\nBaseline Performance:\")\n    print(f\"  Accuracy: {all_results['baseline']['accuracy']:.4f}\")\n    print(f\"  True Signal Recall: {all_results['baseline']['true_recall']:.4f}\")\n    print(f\"  True Signal Precision: {all_results['baseline']['true_precision']:.4f}\")\n    \n    if threshold_results:\n        best_threshold = max(threshold_results, key=lambda x: x['accuracy'])\n        print(f\"\\nBest Threshold Result:\")\n        print(f\"  Threshold: {best_threshold['threshold']*100:.3f}%\")\n        print(f\"  Accuracy: {best_threshold['accuracy']:.4f}\")\n        improvement = (best_threshold['accuracy'] - all_results['baseline']['accuracy']) * 100\n        print(f\"  Improvement: {improvement:+.2f}%\")\n    \n    if all_results['weight_results']:\n        best_weight = max(all_results['weight_results'], key=lambda x: x['accuracy'])\n        print(f\"\\nBest Weight Result:\")\n        print(f\"  Weight: {best_weight['scale_pos_weight']}\")\n        print(f\"  Accuracy: {best_weight['accuracy']:.4f}\")\n    \n    return all_results\n\n\ndef main():\n    import argparse\n    \n    parser = argparse.ArgumentParser(description=\"Optimize ML signal classifier\")\n    parser.add_argument(\n        \"--strategy\",\n        type=str,\n        default=\"threshold\",\n        choices=[\"threshold\", \"weight\", \"holdperiod\", \"all\"],\n        help=\"Optimization strategy to test (default: threshold)\"\n    )\n    parser.add_argument(\n        \"--lookback\",\n        type=int,\n        default=5000,\n        help=\"Lookback period for training (default: 5000)\"\n    )\n    \n    args = parser.parse_args()\n    \n    if args.strategy == \"threshold\":\n        strategy_threshold_optimization()\n    elif args.strategy == \"weight\":\n        strategy_class_weight_optimization()\n    elif args.strategy == \"holdperiod\":\n        strategy_hold_period_optimization()\n    elif args.strategy == \"all\":\n        compare_all_strategies()\n\n\nif __name__ == \"__main__\":\n    main()\n